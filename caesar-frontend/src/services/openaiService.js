/**
 * OpenAI API ì„œë¹„ìŠ¤
 * ì‹¤ì œ GPT-4ë¥¼ ì‚¬ìš©í•œ ì§€ëŠ¥í˜• ì‘ë‹µ ìƒì„±
 */

import OpenAI from 'openai'

class OpenAIService {
  constructor() {
    // í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
    const apiKey = import.meta.env.VITE_OPENAI_API_KEY
    
    if (!apiKey || apiKey === 'your_openai_api_key_here') {
      console.log('ðŸ”§ ê°œë°œ ëª¨ë“œ: OpenAI API í‚¤ ì—†ì´ ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ìž‘ë™í•©ë‹ˆë‹¤.')
      this.openai = null
      this.isConfigured = false
      return
    }

    // OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    this.openai = new OpenAI({
      apiKey: apiKey,
      dangerouslyAllowBrowser: true // ë¸Œë¼ìš°ì €ì—ì„œ ì‚¬ìš© í—ˆìš©
    })

    this.isConfigured = true
    this.conversationHistory = []
    this.isProcessing = false

    // ì„¤ì •ê°’ë“¤
    this.model = import.meta.env.VITE_OPENAI_MODEL || 'gpt-4'
    this.maxTokens = parseInt(import.meta.env.VITE_OPENAI_MAX_TOKENS) || 2000
    this.temperature = parseFloat(import.meta.env.VITE_OPENAI_TEMPERATURE) || 0.7

    console.log('âœ… OpenAI ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.')
  }

  // OpenAI ì„¤ì • ìƒíƒœ í™•ì¸
  isReady() {
    return this.isConfigured && this.openai !== null
  }

  // ë©”ì‹œì§€ ì²˜ë¦¬ ë° OpenAI ì‘ë‹µ ìƒì„±
  async processMessage(message, userId = 'user') {
    if (!this.isReady()) {
      throw new Error('OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.')
    }

    if (this.isProcessing) {
      throw new Error('ì´ì „ ìš”ì²­ì´ ì²˜ë¦¬ ì¤‘ìž…ë‹ˆë‹¤.')
    }

    this.isProcessing = true

    try {
      // ëŒ€í™” ížˆìŠ¤í† ë¦¬ì— ì‚¬ìš©ìž ë©”ì‹œì§€ ì¶”ê°€
      this.conversationHistory.push({
        role: 'user',
        content: message
      })

      // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
      const systemPrompt = this.getSystemPrompt()
      
      // OpenAI API í˜¸ì¶œì„ ìœ„í•œ ë©”ì‹œì§€ ë°°ì—´ êµ¬ì„±
      const messages = [
        { role: 'system', content: systemPrompt },
        ...this.conversationHistory.slice(-10) // ìµœê·¼ 10ê°œ ëŒ€í™”ë§Œ ìœ ì§€
      ]

      console.log('ðŸ¤– OpenAI API í˜¸ì¶œ ì¤‘...')

      // OpenAI API í˜¸ì¶œ
      const completion = await this.openai.chat.completions.create({
        model: this.model,
        messages: messages,
        max_tokens: this.maxTokens,
        temperature: this.temperature,
        stream: false
      })

      const response = completion.choices[0].message.content

      // ëŒ€í™” ížˆìŠ¤í† ë¦¬ì— AI ì‘ë‹µ ì¶”ê°€
      this.conversationHistory.push({
        role: 'assistant',
        content: response
      })

      console.log('âœ… OpenAI ì‘ë‹µ ìƒì„± ì™„ë£Œ')

      return {
        success: true,
        response,
        conversationId: `conv_${Date.now()}`,
        model: this.model,
        tokensUsed: completion.usage?.total_tokens || 0
      }

    } catch (error) {
      console.error('âŒ OpenAI API ì˜¤ë¥˜:', error)
      
      // API ì˜¤ë¥˜ ë©”ì‹œì§€ ì²˜ë¦¬
      let errorMessage = 'OpenAI API ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
      
      if (error.code === 'invalid_api_key') {
        errorMessage = 'OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. .env íŒŒì¼ì˜ API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.'
      } else if (error.code === 'insufficient_quota') {
        errorMessage = 'OpenAI API ì‚¬ìš©ëŸ‰ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ìš”ê¸ˆì œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.'
      } else if (error.code === 'rate_limit_exceeded') {
        errorMessage = 'API í˜¸ì¶œ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ìž ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
      }

      throw new Error(errorMessage)
      
    } finally {
      this.isProcessing = false
    }
  }

  // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
  getSystemPrompt() {
    return `ë‹¹ì‹ ì€ Caesar AI Assistantìž…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ì‘ë‹µì„ ì œê³µí•˜ëŠ” íšŒì‚¬ ë‚´ë¶€ AI ì–´ì‹œìŠ¤í„´íŠ¸ìž…ë‹ˆë‹¤.

**ì—­í• ê³¼ íŠ¹ì§•:**
- íšŒì‚¬ ì—…ë¬´ë¥¼ ë„ì™€ì£¼ëŠ” ì „ë¬¸ì ì´ë©´ì„œë„ ì¹œê·¼í•œ ì–´ì‹œìŠ¤í„´íŠ¸
- ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ ì •ë³´ ì œê³µ
- ì ì ˆí•œ ì´ëª¨ì§€ ì‚¬ìš©ìœ¼ë¡œ ì¹œê·¼í•¨ í‘œí˜„
- ëª¨ë¥´ëŠ” ê²ƒì€ ì†”ì§í•˜ê²Œ ì¸ì •í•˜ê³  ëŒ€ì•ˆ ì œì‹œ

**ì£¼ìš” ì—…ë¬´ ì˜ì—­:**
ðŸ“‹ íšŒì‚¬ ê·œì • ë° ì •ì±… ì•ˆë‚´
ðŸ’¼ ì—…ë¬´ í”„ë¡œì„¸ìŠ¤ ì§€ì›
ðŸ“… ì¼ì • ë° íšŒì˜ ê´€ë¦¬
ðŸ“„ ë¬¸ì„œ ìž‘ì„± ë° ì •ë¦¬
ðŸ¤ íŒ€ í˜‘ì—… ì§€ì›
ðŸ’» ê¸°ìˆ  ê´€ë ¨ ë„ì›€

**ì‘ë‹µ ìŠ¤íƒ€ì¼:**
- ì¡´ëŒ“ë§ ì‚¬ìš©
- êµ¬ì¡°í™”ëœ ì •ë³´ ì œê³µ (ë¶ˆë¦¿ í¬ì¸íŠ¸, ë²ˆí˜¸ ë“±)
- ì‹¤ìš©ì ì´ê³  actionableí•œ ì¡°ì–¸
- í•„ìš”ì‹œ ì¶”ê°€ ì§ˆë¬¸ ìœ ë„

í•­ìƒ ë„ì›€ì´ ë˜ê³  ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ë ¤ê³  ë…¸ë ¥í•˜ì„¸ìš”.`
  }

  // ëŒ€í™” ížˆìŠ¤í† ë¦¬ ì¡°íšŒ
  getConversationHistory() {
    return this.conversationHistory.map(msg => ({
      role: msg.role,
      content: msg.content,
      timestamp: new Date().toISOString()
    }))
  }

  // ëŒ€í™” ížˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
  clearConversationHistory() {
    this.conversationHistory = []
    console.log('ðŸ—‘ï¸ ëŒ€í™” ížˆìŠ¤í† ë¦¬ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.')
  }

  // í˜„ìž¬ ì²˜ë¦¬ ìƒíƒœ í™•ì¸
  isCurrentlyProcessing() {
    return this.isProcessing
  }

  // ì„¤ì • ì •ë³´ ì¡°íšŒ
  getSettings() {
    return {
      model: this.model,
      maxTokens: this.maxTokens,
      temperature: this.temperature,
      isConfigured: this.isConfigured,
      conversationLength: this.conversationHistory.length
    }
  }

  // ëª¨ë¸ ë³€ê²½ (ëŸ°íƒ€ìž„ì—ì„œ)
  setModel(model) {
    if (['gpt-4', 'gpt-4-turbo', 'gpt-3.5-turbo'].includes(model)) {
      this.model = model
      console.log(`ðŸ”„ ëª¨ë¸ì´ ${model}ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.`)
    } else {
      console.warn(`âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ìž…ë‹ˆë‹¤: ${model}`)
    }
  }

  // Temperature ì¡°ì •
  setTemperature(temp) {
    if (temp >= 0 && temp <= 2) {
      this.temperature = temp
      console.log(`ðŸŒ¡ï¸ Temperatureê°€ ${temp}ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.`)
    } else {
      console.warn('âš ï¸ TemperatureëŠ” 0ê³¼ 2 ì‚¬ì´ì˜ ê°’ì´ì–´ì•¼ í•©ë‹ˆë‹¤.')
    }
  }
}

export default new OpenAIService()
